{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1QKSpVR_AQABrxKIgleCnvg221A_kyK9C","timestamp":1747934223080},{"file_id":"1siCsJYwDsGgDKWzDdxp9zEDzWtfDfzsF","timestamp":1747919159120},{"file_id":"1GqZu6zmCy2vMNMZqO78DDuHvwv_9vJcp","timestamp":1747858525797},{"file_id":"1IzPbxNFQmmSYk9s14L4YjBfUgACn9mW2","timestamp":1593978024316},{"file_id":"1G7NKeneJNyRtcRxLVbbF9jYtRyuTOa-R","timestamp":1592749700622},{"file_id":"https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0/blob/master/Utils/Colab_25GBRAM_GPU.ipynb","timestamp":1592043804148}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4cbgwZWWfWpp"},"source":["# New Section"]},{"cell_type":"markdown","source":["\n","\n","> # Cellule 1 : Téléchargement et Préparation Initiale des Données\n","\n","\n","\n"],"metadata":{"id":"4AcjizET6ia7"}},{"cell_type":"code","source":["import json\n","import requests\n","import os\n","\n","# URL vers le fichier de données brut sur GitHub\n","data_url = \"https://raw.githubusercontent.com/chaimaElouichouany/LLM-Powered-Automated-Incident-Response-and-Playbook-Generation/main/display-all-training-data%20(1).json\"\n","\n","print(f\"Téléchargement des données depuis : {data_url}\")\n","# Téléchargement des données\n","try:\n","    response = requests.get(data_url)\n","    response.raise_for_status() # Vérifie si la requête a réussi\n","    data = response.json()\n","    print(\"Données téléchargées avec succès.\")\n","\n","    # Extraction de tous les textes du champ \"text\"\n","    all_texts = []\n","    for item in data:\n","        if \"text\" in item:\n","            all_texts.append(item[\"text\"])\n","\n","    # Fusion de tous les textes en une seule grande chaîne de caractères, séparés par un saut de ligne\n","    training_data_string = \"\\n\".join(all_texts)\n","\n","    # Sauvegarde des données dans input.txt dans le répertoire /content/\n","    output_initial_path = \"/content/input.txt\"\n","    with open(output_initial_path, \"w\", encoding=\"utf-8\") as f:\n","        f.write(training_data_string)\n","\n","    print(f\"Données sauvegardées dans {output_initial_path}\")\n","    print(f\"Nombre total de caractères dans les données d'entraînement : {len(training_data_string)}\")\n","    print(f\"Nombre d'exemples (playbooks) dans les données : {len(all_texts)}\")\n","\n","except requests.exceptions.RequestException as e:\n","    print(f\"Erreur lors du téléchargement des données : {e}\")\n","except json.JSONDecodeError as e:\n","    print(f\"Erreur lors du décodage du JSON : {e}\")\n","except Exception as e:\n","    print(f\"Une erreur inattendue est survenue (Cellule 1) : {e}\")"],"metadata":{"id":"fMqpZnalbzSp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748358943628,"user_tz":-120,"elapsed":409,"user":{"displayName":"chaima el-ouichouany","userId":"10164592286745278442"}},"outputId":"d8d05b6d-1493-4a78-cbe7-6fd41492aadd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Téléchargement des données depuis : https://raw.githubusercontent.com/chaimaElouichouany/LLM-Powered-Automated-Incident-Response-and-Playbook-Generation/main/display-all-training-data%20(1).json\n","Données téléchargées avec succès.\n","Données sauvegardées dans /content/input.txt\n","Nombre total de caractères dans les données d'entraînement : 362468\n","Nombre d'exemples (playbooks) dans les données : 49\n"]}]},{"cell_type":"markdown","source":["# Cellule 2 : Clonage de nanoGPT et Installation des Dépendances"],"metadata":{"id":"_kS2NHmx6zPt"}},{"cell_type":"code","source":["import os\n","\n","print(\"Clonage du dépôt nanoGPT...\")\n","!git clone https://github.com/karpathy/nanogpt.git\n","\n","# Déplacement vers le dossier nanogpt\n","try:\n","    %cd nanogpt\n","    print(f\"Répertoire actuel : {os.getcwd()}\") # os.getcwd() nécessite 'import os'\n","\n","    print(\"Installation de tiktoken...\")\n","    !pip install tiktoken\n","    print(\"Dépendances installées.\")\n","except Exception as e:\n","    print(f\"Une erreur est survenue lors du clonage ou de l'installation (Cellule 2) : {e}\")\n","    print(\"Veuillez vérifier si le dépôt a été cloné et si vous êtes dans le bon répertoire.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQN4NrHYdiXd","executionInfo":{"status":"ok","timestamp":1748349628132,"user_tz":-120,"elapsed":2725,"user":{"displayName":"chaima el-ouichouany","userId":"10164592286745278442"}},"outputId":"d400a616-1204-4514-a319-3e80aa68a469"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Clonage du dépôt nanoGPT...\n","Cloning into 'nanogpt'...\n","remote: Enumerating objects: 686, done.\u001b[K\n","remote: Total 686 (delta 0), reused 0 (delta 0), pack-reused 686 (from 1)\u001b[K\n","Receiving objects: 100% (686/686), 954.04 KiB | 20.30 MiB/s, done.\n","Resolving deltas: 100% (387/387), done.\n","/content/nanogpt/nanogpt\n","Répertoire actuel : /content/nanogpt/nanogpt\n","Installation de tiktoken...\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n","Dépendances installées.\n"]}]},{"cell_type":"markdown","source":["# Cellule 3 : Organisation des Données pour nanoGPT"],"metadata":{"id":"ykfVFtib69fF"}},{"cell_type":"code","source":["import os\n","import shutil\n","\n","expected_base_dir = \"/content\"\n","if os.getcwd().endswith(\"/nanogpt\"):\n","    %cd ..\n","    print(f\"Changé de répertoire vers : {os.getcwd()}\")\n","elif os.getcwd() != expected_base_dir:\n","    %cd {expected_base_dir}\n","    print(f\"Changé de répertoire vers : {os.getcwd()}\")\n","else:\n","    print(f\"Déjà dans le répertoire : {os.getcwd()}\")\n","\n","nanogpt_base_dir = \"/content/nanogpt\"\n","nanogpt_data_dir = os.path.join(nanogpt_base_dir, \"data\", \"incident_playbooks\")\n","\n","print(f\"Création du répertoire (s'il n'existe pas) : {nanogpt_data_dir}\")\n","os.makedirs(nanogpt_data_dir, exist_ok=True)\n","\n","source_input_file = \"/content/input.txt\"\n","destination_input_file = os.path.join(nanogpt_data_dir, \"input.txt\")\n","\n","print(f\"Tentative de déplacement de {source_input_file} vers {destination_input_file}\")\n","if os.path.exists(source_input_file):\n","    try:\n","        shutil.move(source_input_file, destination_input_file)\n","        print(\"Fichier déplacé avec succès.\")\n","    except Exception as e:\n","        print(f\"Erreur lors du déplacement du fichier avec shutil : {e}\")\n","        print(\"Tentative avec !mv en fallback...\")\n","        !mv {source_input_file} {destination_input_file}\n","else:\n","    print(f\"ERREUR : Fichier source {source_input_file} non trouvé. Assurez-vous que la Cellule 1 s'est exécutée correctement.\")\n","\n","# Vérification de l'existence du fichier à la nouvelle destination\n","if os.path.exists(destination_input_file):\n","    print(f\"Confirmé : {destination_input_file} existe.\")\n","else:\n","    print(f\"ERREUR : {destination_input_file} n'existe pas après l'opération de déplacement.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K6q8NHeqdrSW","executionInfo":{"status":"ok","timestamp":1748349628156,"user_tz":-120,"elapsed":19,"user":{"displayName":"chaima el-ouichouany","userId":"10164592286745278442"}},"outputId":"3414de26-a212-422f-9ccc-d65d722e3e95"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/nanogpt\n","Changé de répertoire vers : /content/nanogpt\n","Création du répertoire (s'il n'existe pas) : /content/nanogpt/data/incident_playbooks\n","Tentative de déplacement de /content/input.txt vers /content/nanogpt/data/incident_playbooks/input.txt\n","Fichier déplacé avec succès.\n","Confirmé : /content/nanogpt/data/incident_playbooks/input.txt existe.\n"]}]},{"cell_type":"markdown","source":["# Cellule 4  : Création du script prepare.py pour votre jeu de données\n"],"metadata":{"id":"NEX4OdO87YjO"}},{"cell_type":"code","source":["%%writefile /content/nanogpt/data/incident_playbooks/prepare.py\n","import os\n","import pickle\n","import tiktoken # tiktoken est utilisé pour le BPE de GPT-2\n","import numpy as np\n","\n","# Chemin vers le fichier input.txt\n","input_file_path = os.path.join(os.path.dirname(__file__), 'input.txt')\n","# Répertoire de sortie\n","output_dir = os.path.dirname(__file__)\n","\n","if not os.path.exists(input_file_path):\n","    print(f\"Erreur : {input_file_path} non trouvé.\")\n","    exit()\n","\n","print(f\"Lecture des données depuis {input_file_path}...\")\n","with open(input_file_path, 'r', encoding='utf-8') as f:\n","    data = f.read()\n","print(f\"Données lues. Longueur totale : {len(data)} caractères.\")\n","\n","# Division des données : 90% pour l'entraînement, 10% pour la validation\n","n = len(data)\n","train_data = data[:int(n*0.9)]\n","val_data = data[int(n*0.9):]\n","\n","# Encodage avec le tokenizer GPT-2 de tiktoken (BPE)\n","print(\"Encodage des données avec tiktoken (gpt2)...\")\n","enc = tiktoken.get_encoding(\"gpt2\")\n","train_ids = enc.encode_ordinary(train_data) # Utiliser encode_ordinary pour du texte brut\n","val_ids = enc.encode_ordinary(val_data)\n","print(f\"Entraînement : {len(train_ids):,} tokens\")\n","print(f\"Validation : {len(val_ids):,} tokens\")\n","\n","# Exportation vers des fichiers .bin\n","print(\"Exportation des IDs de tokens vers des fichiers .bin...\")\n","train_ids_np = np.array(train_ids, dtype=np.uint16)\n","val_ids_np = np.array(val_ids, dtype=np.uint16)\n","train_ids_np.tofile(os.path.join(output_dir, 'train.bin'))\n","val_ids_np.tofile(os.path.join(output_dir, 'val.bin'))\n","print(\"train.bin et val.bin créés.\")\n","\n","print(\"Préparation des données terminée (sans création de meta.pkl).\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N0FZFTnDeDkO","executionInfo":{"status":"ok","timestamp":1748349630427,"user_tz":-120,"elapsed":6,"user":{"displayName":"chaima el-ouichouany","userId":"10164592286745278442"}},"outputId":"f19a83fb-984d-483f-c6d1-3afdfb6bab99"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/nanogpt/data/incident_playbooks/prepare.py\n"]}]},{"cell_type":"markdown","source":["# Cellule 5 : Exécution de prepare.py et suppression de l'ancien meta.pkl\n"],"metadata":{"id":"AH8xORy272us"}},{"cell_type":"code","source":["import os\n","\n","prepare_script_dir = \"/content/nanogpt/data/incident_playbooks/\"\n","%cd {prepare_script_dir}\n","print(f\"Répertoire actuel : {os.getcwd()}\")\n","\n","print(\"Exécution de prepare.py (version qui ne devrait plus créer meta.pkl)...\")\n","!python prepare.py\n","# Suppression explicite de meta.pkl s'il existe d'une exécution précédente\n","meta_file_path = os.path.join(prepare_script_dir, \"meta.pkl\")\n","print(f\"Vérification de l'existence du fichier : {meta_file_path}\")\n","if os.path.exists(meta_file_path):\n","    print(f\"Suppression de l'ancien fichier {meta_file_path}...\")\n","    try:\n","        os.remove(meta_file_path)\n","        print(f\"Fichier {meta_file_path} supprimé avec succès.\")\n","    except Exception as e:\n","        print(f\"Erreur lors de la suppression de {meta_file_path}: {e}\")\n","else:\n","    print(f\"Aucun fichier {meta_file_path} trouvé à supprimer .\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nw6knhbjeNJa","executionInfo":{"status":"ok","timestamp":1748349634614,"user_tz":-120,"elapsed":2028,"user":{"displayName":"chaima el-ouichouany","userId":"10164592286745278442"}},"outputId":"7089e191-d6c4-4e34-9b97-1e031276a2da"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/nanogpt/data/incident_playbooks\n","Répertoire actuel : /content/nanogpt/data/incident_playbooks\n","Exécution de prepare.py (version qui ne devrait plus créer meta.pkl)...\n","Lecture des données depuis /content/nanogpt/data/incident_playbooks/input.txt...\n","Données lues. Longueur totale : 362468 caractères.\n","Encodage des données avec tiktoken (gpt2)...\n","Entraînement : 66,404 tokens\n","Validation : 7,543 tokens\n","Exportation des IDs de tokens vers des fichiers .bin...\n","train.bin et val.bin créés.\n","Préparation des données terminée (sans création de meta.pkl).\n","Vérification de l'existence du fichier : /content/nanogpt/data/incident_playbooks/meta.pkl\n","Aucun fichier /content/nanogpt/data/incident_playbooks/meta.pkl trouvé à supprimer .\n"]}]},{"cell_type":"markdown","source":["# Cellule 6 : Création du fichier de configuration d'entraînement\n"],"metadata":{"id":"2AmpbU3EAfRP"}},{"cell_type":"code","source":["%%writefile /content/nanogpt/config/train_incident_playbooks.py\n","# Configuration pour l'entraînement de nanoGPT sur les playbooks d'incidents\n","\n","out_dir = 'out-incident-playbooks-v4'\n","eval_interval = 500       # Évaluer moins fréquemment pour les longs entraînements\n","log_interval = 50         # Afficher les logs un peu moins fréquemment\n","eval_iters = 100\n","wandb_log = False\n","wandb_project = 'incident-playbooks'\n","wandb_run_name = 'nanogpt-playbook-deeper-train'\n","\n","# --- Données ---\n","dataset = 'incident_playbooks'\n","gradient_accumulation_steps = 1\n","batch_size = 6 # Maintenir à 6 avec block_size=256. Réduire si block_size augmente ou en cas d'erreur mémoire.\n","block_size = 256 # Maintenir pour l'instant. Peut être augmenté à 512 (avec batch_size réduit)\n","\n","# --- Paramètres du Modèle ---\n","n_layer = 6\n","n_head = 6\n","n_embd = 384\n","\n","# --- Paramètres d'Entraînement ---\n","dropout = 0.1                 # Maintenir à 0.1 pour l'instant\n","learning_rate = 6e-4          # Taux d'apprentissage légèrement réduit\n","max_iters = 50000           # Augmentation significative des itérations (جرب 20000-30000)\n","lr_decay_iters =  50000      # Doit correspondre à max_iters\n","min_lr = 6e-5                 # 1/10 du taux d'apprentissage initial\n","compile = False"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zmrahZ34eRvf","executionInfo":{"status":"ok","timestamp":1748349637457,"user_tz":-120,"elapsed":10,"user":{"displayName":"chaima el-ouichouany","userId":"10164592286745278442"}},"outputId":"5f5fefc9-3bd6-4865-ee9f-290350452287"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting /content/nanogpt/config/train_incident_playbooks.py\n"]}]},{"cell_type":"markdown","source":["# Cellule 7 : Démarrage de l'Entraînement\n"],"metadata":{"id":"iAe-H36DBC72"}},{"cell_type":"code","source":["import os\n","\n","# Déplacement vers le répertoire principal de nanoGPT\n","nanogpt_root_dir = \"/content/nanogpt/\"\n","%cd {nanogpt_root_dir}\n","print(f\"Répertoire actuel : {os.getcwd()}\")\n","\n","print(\"Démarrage de l'entraînement ...\")\n","!python train.py config/train_incident_playbooks.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MX9piHnHeV5L","outputId":"63aabe19-2332-4ba8-c816-2173f204aa15","executionInfo":{"status":"ok","timestamp":1748358939017,"user_tz":-120,"elapsed":121,"user":{"displayName":"chaima el-ouichouany","userId":"10164592286745278442"}}},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: '/content/nanogpt/'\n","/content\n","Répertoire actuel : /content\n","Démarrage de l'entraînement ...\n","python3: can't open file '/content/train.py': [Errno 2] No such file or directory\n"]}]},{"cell_type":"markdown","source":["# Cellule 8 : Génération de texte à partir du modèle entraîné\n"],"metadata":{"id":"rR031YVNBL5K"}},{"cell_type":"code","source":["# Cell 8: Sample from the Trained Model\n","import os\n","\n","# Make sure this is the directory of the model you want to test\n","output_directory_name = 'out-incident-playbooks-v4'\n","\n","checkpoint_path = f\"/content/nanogpt/{output_directory_name}/ckpt.pt\"\n","\n","if os.path.exists(checkpoint_path):\n","    print(f\"Testing model from checkpoint: {checkpoint_path}\")\n","\n","    # ---- MODIFY THE PROMPT BELOW FOR EACH TEST ----\n","    prompt = \"<s>[INST] Please generate a detailed playbook for a DDOS  attack [/INST]\"\n","\n","    !python sample.py \\\n","        --out_dir={output_directory_name} \\\n","        --start=\"{prompt}\" \\\n","        --num_samples=1 \\\n","        --max_new_tokens=400 # Increased tokens to see more of the playbook\n","else:\n","    print(f\"Checkpoint file not found in {checkpoint_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5DpvIrdpiI-h","executionInfo":{"status":"ok","timestamp":1748097246372,"user_tz":-120,"elapsed":7379,"user":{"displayName":"chaima el-ouichouany","userId":"10164592286745278442"}},"outputId":"4be46801-04a6-4e57-f0e1-9488d2e609a0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing model from checkpoint: /content/nanogpt/out-incident-playbooks-v3/ckpt.pt\n","Overriding: out_dir = out-incident-playbooks-v3\n","Overriding: start = <s>[INST] Please generate a detailed playbook for a Ransomware attack [/INST]\n","Overriding: num_samples = 1\n","Overriding: max_new_tokens = 400\n","number of parameters: 29.94M\n","No meta.pkl found, assuming GPT-2 encodings...\n","<s>[INST] Please generate a detailed playbook for a Ransomware attack [/INST] Sure. Here is the information requested.\n","Title: : Incident Response Playbook for Phishing Attack\n","1. Preparation: : Objective: Establish Contacts, Define Procedures, Gather Information to Save Time During an Incident\n","1.1 Policies and Procedures\n","Develop and Document Policies: Create detailed policies and procedures for incident response, specifically for phishing attacks.\n","Employee Training: Conduct regular training sessions to educate employees on recognizing phishing attempts and the importance of reporting suspicious emails.\n","Incident Reporting Mechanism: Establish clear channels for reporting suspected phishing attempts (e.g., a dedicated email address or an internal reporting tool).\n","Regular Updates: Regularly update all incident response documentation and ensure it is accessible to all relevant personnel.\n","1.2 Incident Response Team (IRT)\n","Define Roles and Responsibilities: Clearly outline the roles and responsibilities within the IRT, including first responders, analysts, and communication coordinators.\n","Access Control: Ensure the IRT has the necessary access to systems, logs, and tools to effectively respond to incidents.\n","Tool Inventory: Maintain an inventory of tools and technologies needed for incident response, such as email filtering solutions, endpoint detection and response (EDR) tools, and forensic analysis tools.\n","1.3 Internal Communication\n","Regular Updates: Provide regular updates to all stakeholders throughout the incident response process.\n","1.4 External Communication\n","Customer Notification: Notify customers if their information was compromised. Provide guidance on steps they should take to protect themselves.\n","2. Detection and Analysis: : Objective: Detect the Incident, determine its Scope, and Involve the Appropriate Parties\n","2.1 Incident Identification\n","Monitoring and Alerts: Implement monitoring systems to detect phishing attempts, such as email filters, SIEM (Security Information and Event Management) systems, and user behavior analytics.\n","Employee Reports: Encourage employees to report suspicious emails immediately. Provide clear instructions on how to report these incidents\n","---------------\n"]}]}]}